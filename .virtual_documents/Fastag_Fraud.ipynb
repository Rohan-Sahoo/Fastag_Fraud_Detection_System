import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns





df = pd.read_csv("FastagFraudDetection.csv")


df.info()


df.isnull().sum()


df.duplicated().sum()





#Description  of data set
df.describe()


print(df.columns)


print("Unique Vehicle Type: ",df['Vehicle_Type'].unique())
print("Unique Vehicle Dimension: ",df['Vehicle_Dimensions'].unique())
print("Unique Toll Booth ID: ",df['TollBoothID'].unique())
print("Unique Lane Type: ",df['Lane_Type'].unique())
print("Unique Fraud Indicator: ",df['Fraud_indicator'].unique())
print("Unique Geographical Location: ",df['Geographical_Location'].unique())





print(df['Fraud_indicator'].value_counts())


df['Fraud_indicator'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.title("Fraud Indicator Percentage")
plt.axis('equal')
plt.show()





sns.countplot(x='Vehicle_Type',
              data=df,
              hue='Fraud_indicator').set_title("Vehicle Type")


sns.countplot(x="Vehicle_Dimensions",
              data=df,
              hue="Fraud_indicator").set_title("Vehicle Dimensions")


sns.countplot(x="TollBoothID",
              data=df,
              hue="Fraud_indicator").set_title("Toll Booth ID")


sns.countplot(x="Lane_Type",
              data=df,
              hue="Fraud_indicator").set_title("Lane Type")


fig,axes=plt.subplots(2,2,figsize=(10,8))
#For vehicle type
sns.countplot(x='Vehicle_Type',
              data=df,
              hue='Fraud_indicator',
             ax=axes[0,0]).set_title("Vehicle Type")

#For Vehicle Dimensions
sns.countplot(x="Vehicle_Dimensions",
              data=df,
              hue="Fraud_indicator",
             ax=axes[0,1]).set_title("Vehicle Dimensions")

# For Toll Both ID
sns.countplot(x="TollBoothID",
              data=df,
              hue="Fraud_indicator",
             ax=axes[1,0]).set_title("Toll Booth ID")

# For Lane Type
sns.countplot(x="Lane_Type",
              data=df,
              hue="Fraud_indicator",
             ax=axes[1,1]).set_title("Lane Type")

plt.suptitle("Fraud Analysis based on different features")
plt.tight_layout()









df.columns


sns.histplot(df['Transaction_Amount'],bins=30,kde=True)
plt.title("Transaction Distribution")
plt.show()


sns.histplot(df['Amount_paid'],bins=30,kde=True)
plt.title("Paid Amount Distribution")
plt.show()


sns.histplot(df['Vehicle_Speed'],bins=30,kde=True)
plt.title("Vehicle Distribution")
plt.show()





sns.scatterplot(x="Transaction_Amount",
                y="Amount_paid",
                hue="Fraud_indicator",
                data=df)
plt.title("Transaction Amt vs Paid Amt")
plt.grid()





#pairs
sns.pairplot(df)
plt.tight_layout()





df.info()


df.isnull().sum()


df['state_code']=df['Vehicle_Plate_Number'].str[:2]


df


#Removing Vehicle plate number feature
df=df.drop('Vehicle_Plate_Number',axis=1)


df


# Visualising the fraud based on state code
sns.countplot(x='state_code',
              data=df,
              hue='Fraud_indicator')
plt.title("Fraud Transaction Count based on State Code")
plt.show()


df.loc[df['Fraud_indicator']=='Fraud','state_code'].value_counts()





# Analysing Fraud/Not Fraud on the basis of timestamp
df['Timestamp']


#Converting the timesstamp type (object->date time 64)
df['Timestamp']=pd.to_datetime(df['Timestamp'])


df.info()


df['Hours']=df['Timestamp'].dt.hour
df['DayofWeek']=df['Timestamp'].dt.dayofweek
df['Month']=df['Timestamp'].dt.month


df.head()


# Removing Timestamp feature
df = df.drop('Timestamp',axis=1)


df.head()


df['DayofWeek'].value_counts()


#Visualising Fruads as per week day
sns.countplot(x='DayofWeek',
              data=df,
              hue='Fraud_indicator')
plt.title("Fraud Activity based on Week Days")
plt.xticks([0,1,2,3,4,5,6],["Mon","Tues","Wed","Thurs","Fri","Sat","Sun"])
plt.show()





numericaldf=df.select_dtypes('number')


numericaldf


cor_matrix=numericaldf.corr()
cor_matrix


#Visualising Corelation Matrix
plt.figure(figsize=(10,6))
sns.heatmap(cor_matrix,
            cmap='coolwarm',
            annot=True,
           linewidth=2)
plt.title("Correlation Data")
plt.show()
            





df.columns


df.drop(['Transaction_ID','FastagID','Geographical_Location'],axis=1,inplace=True)


df.info()





from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()


df.columns


objects=['Vehicle_Type','TollBoothID','Lane_Type','Vehicle_Dimensions','Fraud_indicator','state_code']
label_encoder={}
for column in objects:
    le=LabelEncoder()
    df[column]=le.fit_transform(df[column])
    label_encoder[column]=le


df.head()


label_encoder


# How to obtain classes from label encoder
for column in objects:
    print("For ",column,":",label_encoder[column].classes_)





X=df.drop(columns=['Fraud_indicator'])
y=df['Fraud_indicator']


#Splitting 
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y)


# Dimensions of datasets
print("X-Train: ",X_train.shape)
print("X-Test: ",X_test.shape)
print("y-Train: ",y_train.shape)
print("y-Test: ",y_test.shape)





accuracy=[]
precision=[]





from sklearn.linear_model import LogisticRegression
lr_model=LogisticRegression()
lr_model


#Now Fit the Model
lr_model.fit(X_train,y_train)


#Pridiction
y_predict=lr_model.predict(X_test)
y_predict





from sklearn.metrics import classification_report,accuracy_score,precision_score, recall_score,f1_score,confusion_matrix
                    


print(classification_report(y_test,y_predict))





acc=accuracy_score(y_test,y_predict)
prc=precision_score(y_test,y_predict)
rec=recall_score(y_test,y_predict)
conf_mat=confusion_matrix(y_test,y_predict)
f1=f1_score(y_test,y_predict)
accuracy.append(acc)
precision.append(prc)


print("Model Result:")
print("\nModel Accuracy : ",acc)
print("\nModel Precision : ",prc)
print("\nModel Recall : ",rec)
print("\nConfusion Matrix: \n",conf_mat)
print("\nModel F1 Score: ",f1)



#Functionto Evaluation Model
def model_evaluation(y_test,y_predict,accuracy,precision):
    acc=accuracy_score(y_test,y_predict)
    prc=precision_score(y_test,y_predict)
    rec=recall_score(y_test,y_predict)
    conf_mat=confusion_matrix(y_test,y_predict)
    f1=f1_score(y_test,y_predict)
    accuracy.append(acc)
    precision.append(prc)

    print("Model Result:")
    print("\nModel Accuracy : ",acc)
    print("\nModel Precision : ",prc)
    print("\nModel Recall : ",rec)
    print("\nConfusion Matrix: \n",conf_mat)
    print("\nModel F1 Score: ",f1)



# Importing Models
from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier





#Decision Tree Classifier Model Training
dec_tree_model=DecisionTreeClassifier()
dec_tree_model.fit(X_train,y_train)


#Predicition 
dec_tree_predict=dec_tree_model.predict(X_test)


#Evaluation
print("Model Evaluation for Decision Tree Classifier\n")
model_evaluation(y_test,dec_tree_predict,accuracy,precision)





rand_forest_model=RandomForestClassifier()
rand_forest_model.fit(X_train,y_train) #Fitting
randforest_predict=rand_forest_model.predict(X_test) #Prediction
print("Model Evaluation for Random Forest Classifier\n")
model_evaluation(y_test,randforest_predict,accuracy,precision)






from sklearn.svm import SVC
svc_model=SVC()
svc_model.fit(X_train,y_train) # Fitting the model
svc_predict=svc_model.predict(X_test) #Prediction
print("Model Evaluation for Support Vector Classifier Machine \n")
model_evaluation(y_test,svc_predict,accuracy,precision)






from sklearn.neighbors import KNeighborsClassifier


knn_model=KNeighborsClassifier(n_neighbors=3)
knn_model


knn_model.fit(X_train,y_train) # Fitting
knn_model_predict=knn_model.predict(X_test) # Model Prediction
print("Model Evaluation for K-Neighbors Classifier\n")
model_evaluation(y_test,knn_model_predict,accuracy,precision)





models=["Logistic Regression","Decision Tree","Random Forest","SCV-Machine","K-N-N"]
plt.figure(figsize=(10,10))
plt.bar(models,
        accuracy)

plt.title("Accuracy Comparison")
plt.xlabel("ML-Model")
plt.ylabel("Accuracy Score")
plt.show()

print("From the above Visualisation :")
m=max(accuracy)
i=accuracy.index(m)
print(f"ML-Model {models[i]} has highest Accouracy of {m*100}%\n")


models=["Logistic Regression","Decision Tree","Random Forest","SCV-Machine","K-N-N"]
plt.figure(figsize=(10,10))
plt.bar(models,
        precision)

plt.title("Precision Comparison")
plt.xlabel("ML-Model")
plt.ylabel("Precision Score")
plt.show()

print("From the above Visualisation :")
m=max(precision)
i=precision.index(m)

print(f"ML-Model {models[i]} has highest Precision of {round(m,5)*100}%\n")








from sklearn.model_selection import RandomizedSearchCV


rf_params={'max_depth':[5,8,15,20,None],
           'max_features':list(range(1, X_train.shape[1] + 1)),
           'min_samples_split':[2,8,15],
           'n_estimators':[100,200,500]}



randomcv_models=[("RF", RandomForestClassifier(),rf_params)
                ]


model_params={}
for name,model,params in randomcv_models:
    random=RandomizedSearchCV(estimator=model,
                              param_distributions=params,
                              n_iter=20,
                              cv=3,
                              verbose=2,
                              n_jobs=1,
                              error_score='raise')
    random.fit(X_train,y_train)
    model_params[name]=random.best_params_
    
                              


 model_params





rand_forest_model2=RandomForestClassifier(n_estimators= 200,
                                          min_samples_split= 15,
                                          max_features= 9,
                                          max_depth= 15)
rand_forest_model2


rand_forest_model2.fit(X_train,y_train) #Fitting the model
rand_forest_model2_pred=rand_forest_model2.predict(X_test) #Prdicition


print("New result of Random Forest Classifier after aplying Randomized Search CV\n")
model_evaluation(y_test,rand_forest_model2_pred,accuracy,precision)






